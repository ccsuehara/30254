{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "import edited_pipeline as ep\n",
    "import pipeline as p_l\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = p_l.read_data('/Users/csolisu/Downloads/projects_2012_2013.csv')\n",
    "data['days_financed'] = pd.to_datetime(data['datefullyfunded']) - pd.to_datetime(data['date_posted'])\n",
    "data['label'] = data['days_financed'].dt.days.apply(lambda x: 0 if x <= 60 else 1)\n",
    "d_t = pd.get_dummies(data['teacher_prefix'])\n",
    "d_t_lst = list(d_t.columns)\n",
    "d_t['female_teacher'] = d_t['Dr.'] + d_t['Ms.'] + d_t['Mrs.'] \n",
    "d_t['male_teacher'] = d_t['Mr.']\n",
    "p_l.drop_features(d_t, d_t_lst)\n",
    "data.join(d_t)\n",
    "\n",
    "final_drop = ['teacher_prefix']\n",
    "p_l.drop_features(data, final_drop)\n",
    "tf_dic = {'t': 1, 'f':0}\n",
    "data = data.replace({'school_charter': tf_dic, 'school_magnet': tf_dic, 'eligible_double_your_impact_match' : tf_dic})\n",
    "\n",
    "\n",
    "temp_lst = ep.temp_val('2012-01-01','2013-12-31',6,6,60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs, grid = ep.define_clfs_params('small')\n",
    "models_to_run=['RF','DT','LR']\n",
    "metric_lst =[ep.roc_auc_sc,ep.precision_at_k,ep.recall_at_k,ep.f1_at_k]\n",
    "k_lst = [1.0,2.0,5.0,10.0,20.0,30.0,40.0,50.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "i am here\n",
      "[0 1 0 ... 1 0 0]\n",
      "[[ 0.  1. 23. ...  0.  0.  1.]\n",
      " [ 0.  0. 15. ...  0.  0.  0.]\n",
      " [ 0.  0. 24. ...  0.  0.  1.]\n",
      " ...\n",
      " [ 0.  1. 24. ...  0.  0.  1.]\n",
      " [ 0.  0. 20. ...  0.  0.  0.]\n",
      " [ 0.  0. 11. ...  1.  0.  0.]]\n",
      "RF\n",
      "DT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/csolisu/30254/Machine_Learning/hw3/edited_pipeline.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision * recall) / (precision + recall)\n",
      "/Users/csolisu/30254/Machine_Learning/hw3/edited_pipeline.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision * recall) / (precision + recall)\n",
      "/Users/csolisu/30254/Machine_Learning/hw3/edited_pipeline.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision * recall) / (precision + recall)\n",
      "/Users/csolisu/30254/Machine_Learning/hw3/edited_pipeline.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision * recall) / (precision + recall)\n",
      "/Users/csolisu/30254/Machine_Learning/hw3/edited_pipeline.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision * recall) / (precision + recall)\n",
      "/Users/csolisu/30254/Machine_Learning/hw3/edited_pipeline.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision * recall) / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am here\n",
      "[0 1 0 ... 1 0 1]\n",
      "[[  0.   0.  31. ...   0.   0.   1.]\n",
      " [  0.   0. 150. ...   0.   0.   1.]\n",
      " [  0.   0.  37. ...   0.   0.   0.]\n",
      " ...\n",
      " [  0.   0.  25. ...   0.   1.   0.]\n",
      " [  0.   0.   7. ...   0.   0.   1.]\n",
      " [  0.   0.  24. ...   0.   0.   1.]]\n",
      "RF\n",
      "DT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/csolisu/30254/Machine_Learning/hw3/edited_pipeline.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision * recall) / (precision + recall)\n",
      "/Users/csolisu/30254/Machine_Learning/hw3/edited_pipeline.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision * recall) / (precision + recall)\n",
      "/Users/csolisu/30254/Machine_Learning/hw3/edited_pipeline.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision * recall) / (precision + recall)\n",
      "/Users/csolisu/30254/Machine_Learning/hw3/edited_pipeline.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision * recall) / (precision + recall)\n",
      "/Users/csolisu/30254/Machine_Learning/hw3/edited_pipeline.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision * recall) / (precision + recall)\n",
      "/Users/csolisu/30254/Machine_Learning/hw3/edited_pipeline.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision * recall) / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am here\n",
      "[0 1 0 ... 1 1 0]\n",
      "[[  0.   0.  25. ...   0.   0.   0.]\n",
      " [  1.   0.  25. ...   0.   0.   0.]\n",
      " [  0.   1. 809. ...   0.   0.   1.]\n",
      " ...\n",
      " [  0.   0. 738. ...   1.   0.   0.]\n",
      " [  0.   0.  20. ...   0.   0.   0.]\n",
      " [  0.   1. 156. ...   0.   1.   0.]]\n",
      "RF\n",
      "DT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/csolisu/30254/Machine_Learning/hw3/edited_pipeline.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision * recall) / (precision + recall)\n",
      "/Users/csolisu/30254/Machine_Learning/hw3/edited_pipeline.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision * recall) / (precision + recall)\n",
      "/Users/csolisu/30254/Machine_Learning/hw3/edited_pipeline.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision * recall) / (precision + recall)\n",
      "/Users/csolisu/30254/Machine_Learning/hw3/edited_pipeline.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision * recall) / (precision + recall)\n",
      "/Users/csolisu/30254/Machine_Learning/hw3/edited_pipeline.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision * recall) / (precision + recall)\n",
      "/Users/csolisu/30254/Machine_Learning/hw3/edited_pipeline.py:379: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2 * (precision * recall) / (precision + recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "results_df_long = ep.clf_loop(models_to_run,clfs,grid,data,'date_posted','label',temp_lst,metric_lst,k_lst,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = results_df_long.groupby(['train_end_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_classifiers(df,feat,criteria):\n",
    "    \n",
    "    aa = df.groupby([feat])\n",
    "    df[frozenset(dict_key.items())]\n",
    "    for key, gr in aa:\n",
    "        add_ord = gr[[criteria]]\n",
    "        add_ord.drop_duplicates(inplace = True)\n",
    "        add_ord.sort_values(by =criteria,ascending=False,inplace=True)\n",
    "        add_ord[key] = np.arange(len(add_ord))\n",
    "        gr.sort_values(by=criteria, ascending=False,inplace=True)\n",
    "        total_df = pd.merge(gr,add_ord,on = criteria)\n",
    "        total_df = total_df[['model_type','clf','parameters',key]]\n",
    "        df = pd.merge(df,total_df,on = ['model_type','clf','parameters'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-d6abfaad75be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrank_classifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train_end_date'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'p_at_5.0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-108-a2ae92c7230b>\u001b[0m in \u001b[0;36mrank_classifiers\u001b[0;34m(df, feat, criteria)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtotal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0madd_ord\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtotal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_type'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'parameters'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'model_type'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     60\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                          validate=validate)\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    566\u001b[0m                 self.left, self.right)\n\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0mjoin_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mldata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_join_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             (left_indexer,\n\u001b[0;32m--> 777\u001b[0;31m              right_indexer) = self._get_join_indexers()\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_join_indexers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    754\u001b[0m                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                                   \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                                   how=self.how)\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_join_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_join_indexers\u001b[0;34m(left_keys, right_keys, sort, how, **kwargs)\u001b[0m\n\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;31m# get left & right join labels and num. of levels at each location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m     \u001b[0mllab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[0;31m# get flat i8 keys from label lists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_factorize_keys\u001b[0;34m(lk, rk, sort)\u001b[0m\n\u001b[1;32m   1567\u001b[0m     \u001b[0mrizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1569\u001b[0;31m     \u001b[0mllab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1570\u001b[0m     \u001b[0mrlab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable.pyx\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Factorizer.factorize\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_labels\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "df_1 = rank_classifiers(df,'train_end_date','p_at_5.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_ord = df[['p_at_5.0']]\n",
    "#add_ord.sort_values(by ='p_at_5.0',ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "print(add_ord.shape)\n",
    "add_ord.drop_duplicates(inplace = True)\n",
    "add_ord.sort_values(by ='p_at_5.0',ascending=False,inplace=True)\n",
    "add_ord['ranking'] = np.arange(len(add_ord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.merge(df,add_ord,on='p_at_5.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_end_date</th>\n",
       "      <th>model_type</th>\n",
       "      <th>clf</th>\n",
       "      <th>parameters</th>\n",
       "      <th>p_at_1.0</th>\n",
       "      <th>p_at_2.0</th>\n",
       "      <th>p_at_5.0</th>\n",
       "      <th>p_at_10.0</th>\n",
       "      <th>p_at_20.0</th>\n",
       "      <th>p_at_30.0</th>\n",
       "      <th>...</th>\n",
       "      <th>r_at_40.0</th>\n",
       "      <th>r_at_50.0</th>\n",
       "      <th>f1_at_1.0</th>\n",
       "      <th>f1_at_2.0</th>\n",
       "      <th>f1_at_5.0</th>\n",
       "      <th>f1_at_10.0</th>\n",
       "      <th>f1_at_20.0</th>\n",
       "      <th>f1_at_30.0</th>\n",
       "      <th>f1_at_40.0</th>\n",
       "      <th>f1_at_50.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.554545</td>\n",
       "      <td>0.532955</td>\n",
       "      <td>0.497729</td>\n",
       "      <td>0.483651</td>\n",
       "      <td>0.444205</td>\n",
       "      <td>0.420798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571965</td>\n",
       "      <td>0.687445</td>\n",
       "      <td>0.037675</td>\n",
       "      <td>0.070037</td>\n",
       "      <td>0.148964</td>\n",
       "      <td>0.251818</td>\n",
       "      <td>0.367039</td>\n",
       "      <td>0.432248</td>\n",
       "      <td>0.475059</td>\n",
       "      <td>0.498161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.501136</td>\n",
       "      <td>0.493188</td>\n",
       "      <td>0.474796</td>\n",
       "      <td>0.442161</td>\n",
       "      <td>0.420192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570686</td>\n",
       "      <td>0.687685</td>\n",
       "      <td>0.037366</td>\n",
       "      <td>0.065855</td>\n",
       "      <td>0.147604</td>\n",
       "      <td>0.247207</td>\n",
       "      <td>0.365350</td>\n",
       "      <td>0.431626</td>\n",
       "      <td>0.473997</td>\n",
       "      <td>0.498335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.534091</td>\n",
       "      <td>0.512500</td>\n",
       "      <td>0.497729</td>\n",
       "      <td>0.483197</td>\n",
       "      <td>0.445113</td>\n",
       "      <td>0.420873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571086</td>\n",
       "      <td>0.686646</td>\n",
       "      <td>0.036285</td>\n",
       "      <td>0.067349</td>\n",
       "      <td>0.148964</td>\n",
       "      <td>0.251581</td>\n",
       "      <td>0.367789</td>\n",
       "      <td>0.432325</td>\n",
       "      <td>0.474329</td>\n",
       "      <td>0.497582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.515909</td>\n",
       "      <td>0.497727</td>\n",
       "      <td>0.487738</td>\n",
       "      <td>0.478429</td>\n",
       "      <td>0.444659</td>\n",
       "      <td>0.417543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568129</td>\n",
       "      <td>0.686646</td>\n",
       "      <td>0.035050</td>\n",
       "      <td>0.065407</td>\n",
       "      <td>0.145973</td>\n",
       "      <td>0.249099</td>\n",
       "      <td>0.367414</td>\n",
       "      <td>0.428905</td>\n",
       "      <td>0.471873</td>\n",
       "      <td>0.497582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.502273</td>\n",
       "      <td>0.496591</td>\n",
       "      <td>0.496821</td>\n",
       "      <td>0.482516</td>\n",
       "      <td>0.444886</td>\n",
       "      <td>0.416484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562135</td>\n",
       "      <td>0.682730</td>\n",
       "      <td>0.034123</td>\n",
       "      <td>0.065258</td>\n",
       "      <td>0.148692</td>\n",
       "      <td>0.251227</td>\n",
       "      <td>0.367602</td>\n",
       "      <td>0.427816</td>\n",
       "      <td>0.466895</td>\n",
       "      <td>0.494744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.517045</td>\n",
       "      <td>0.495913</td>\n",
       "      <td>0.482970</td>\n",
       "      <td>0.449994</td>\n",
       "      <td>0.428593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578279</td>\n",
       "      <td>0.689763</td>\n",
       "      <td>0.033969</td>\n",
       "      <td>0.067946</td>\n",
       "      <td>0.148420</td>\n",
       "      <td>0.251463</td>\n",
       "      <td>0.371823</td>\n",
       "      <td>0.440255</td>\n",
       "      <td>0.480303</td>\n",
       "      <td>0.499841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>0.497727</td>\n",
       "      <td>0.517045</td>\n",
       "      <td>0.496821</td>\n",
       "      <td>0.483424</td>\n",
       "      <td>0.449881</td>\n",
       "      <td>0.428896</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577799</td>\n",
       "      <td>0.689763</td>\n",
       "      <td>0.033815</td>\n",
       "      <td>0.067946</td>\n",
       "      <td>0.148692</td>\n",
       "      <td>0.251699</td>\n",
       "      <td>0.371729</td>\n",
       "      <td>0.440566</td>\n",
       "      <td>0.479904</td>\n",
       "      <td>0.499841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>0.495455</td>\n",
       "      <td>0.517045</td>\n",
       "      <td>0.495913</td>\n",
       "      <td>0.483651</td>\n",
       "      <td>0.449881</td>\n",
       "      <td>0.428669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577959</td>\n",
       "      <td>0.689683</td>\n",
       "      <td>0.033660</td>\n",
       "      <td>0.067946</td>\n",
       "      <td>0.148420</td>\n",
       "      <td>0.251818</td>\n",
       "      <td>0.371729</td>\n",
       "      <td>0.440333</td>\n",
       "      <td>0.480037</td>\n",
       "      <td>0.499783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>0.495455</td>\n",
       "      <td>0.515909</td>\n",
       "      <td>0.495005</td>\n",
       "      <td>0.482743</td>\n",
       "      <td>0.449767</td>\n",
       "      <td>0.428517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578199</td>\n",
       "      <td>0.689683</td>\n",
       "      <td>0.033660</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.251345</td>\n",
       "      <td>0.371635</td>\n",
       "      <td>0.440177</td>\n",
       "      <td>0.480236</td>\n",
       "      <td>0.499783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.495455</td>\n",
       "      <td>0.515909</td>\n",
       "      <td>0.495913</td>\n",
       "      <td>0.482970</td>\n",
       "      <td>0.449200</td>\n",
       "      <td>0.428820</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577959</td>\n",
       "      <td>0.689523</td>\n",
       "      <td>0.033660</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.148420</td>\n",
       "      <td>0.251463</td>\n",
       "      <td>0.371166</td>\n",
       "      <td>0.440488</td>\n",
       "      <td>0.480037</td>\n",
       "      <td>0.499667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.493182</td>\n",
       "      <td>0.515909</td>\n",
       "      <td>0.493188</td>\n",
       "      <td>0.483878</td>\n",
       "      <td>0.449200</td>\n",
       "      <td>0.428290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578199</td>\n",
       "      <td>0.689523</td>\n",
       "      <td>0.033506</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.147604</td>\n",
       "      <td>0.251936</td>\n",
       "      <td>0.371166</td>\n",
       "      <td>0.439944</td>\n",
       "      <td>0.480236</td>\n",
       "      <td>0.499667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>0.464773</td>\n",
       "      <td>0.447321</td>\n",
       "      <td>0.434832</td>\n",
       "      <td>0.416960</td>\n",
       "      <td>0.397412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.537281</td>\n",
       "      <td>0.646288</td>\n",
       "      <td>0.033197</td>\n",
       "      <td>0.061077</td>\n",
       "      <td>0.133877</td>\n",
       "      <td>0.226399</td>\n",
       "      <td>0.344527</td>\n",
       "      <td>0.408225</td>\n",
       "      <td>0.446251</td>\n",
       "      <td>0.468336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>0.478409</td>\n",
       "      <td>0.439146</td>\n",
       "      <td>0.414623</td>\n",
       "      <td>0.401294</td>\n",
       "      <td>0.385075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520738</td>\n",
       "      <td>0.631903</td>\n",
       "      <td>0.033197</td>\n",
       "      <td>0.062869</td>\n",
       "      <td>0.131431</td>\n",
       "      <td>0.215878</td>\n",
       "      <td>0.331582</td>\n",
       "      <td>0.395553</td>\n",
       "      <td>0.432511</td>\n",
       "      <td>0.457912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.481818</td>\n",
       "      <td>0.462500</td>\n",
       "      <td>0.454587</td>\n",
       "      <td>0.431653</td>\n",
       "      <td>0.415144</td>\n",
       "      <td>0.397109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534884</td>\n",
       "      <td>0.642292</td>\n",
       "      <td>0.032734</td>\n",
       "      <td>0.060778</td>\n",
       "      <td>0.136052</td>\n",
       "      <td>0.224744</td>\n",
       "      <td>0.343026</td>\n",
       "      <td>0.407914</td>\n",
       "      <td>0.444260</td>\n",
       "      <td>0.465441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.461364</td>\n",
       "      <td>0.461364</td>\n",
       "      <td>0.443233</td>\n",
       "      <td>0.424614</td>\n",
       "      <td>0.407651</td>\n",
       "      <td>0.391433</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532326</td>\n",
       "      <td>0.637097</td>\n",
       "      <td>0.031344</td>\n",
       "      <td>0.060629</td>\n",
       "      <td>0.132654</td>\n",
       "      <td>0.221079</td>\n",
       "      <td>0.336835</td>\n",
       "      <td>0.402083</td>\n",
       "      <td>0.442136</td>\n",
       "      <td>0.461677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.456818</td>\n",
       "      <td>0.461364</td>\n",
       "      <td>0.466848</td>\n",
       "      <td>0.447548</td>\n",
       "      <td>0.438415</td>\n",
       "      <td>0.423522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.572604</td>\n",
       "      <td>0.683209</td>\n",
       "      <td>0.031035</td>\n",
       "      <td>0.060629</td>\n",
       "      <td>0.139721</td>\n",
       "      <td>0.233020</td>\n",
       "      <td>0.362255</td>\n",
       "      <td>0.435046</td>\n",
       "      <td>0.475590</td>\n",
       "      <td>0.495092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'log2', 'min_...</td>\n",
       "      <td>0.452273</td>\n",
       "      <td>0.473864</td>\n",
       "      <td>0.460490</td>\n",
       "      <td>0.453224</td>\n",
       "      <td>0.435350</td>\n",
       "      <td>0.413608</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560697</td>\n",
       "      <td>0.673460</td>\n",
       "      <td>0.030726</td>\n",
       "      <td>0.062271</td>\n",
       "      <td>0.137819</td>\n",
       "      <td>0.235976</td>\n",
       "      <td>0.359722</td>\n",
       "      <td>0.424862</td>\n",
       "      <td>0.465700</td>\n",
       "      <td>0.488027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l2'}</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.460227</td>\n",
       "      <td>0.473660</td>\n",
       "      <td>0.468211</td>\n",
       "      <td>0.442275</td>\n",
       "      <td>0.425490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.576760</td>\n",
       "      <td>0.688963</td>\n",
       "      <td>0.030572</td>\n",
       "      <td>0.060479</td>\n",
       "      <td>0.141760</td>\n",
       "      <td>0.243778</td>\n",
       "      <td>0.365444</td>\n",
       "      <td>0.437068</td>\n",
       "      <td>0.479042</td>\n",
       "      <td>0.499262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 'sqrt', 'min_...</td>\n",
       "      <td>0.447727</td>\n",
       "      <td>0.468182</td>\n",
       "      <td>0.485014</td>\n",
       "      <td>0.465713</td>\n",
       "      <td>0.441934</td>\n",
       "      <td>0.418603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.566131</td>\n",
       "      <td>0.681212</td>\n",
       "      <td>0.030418</td>\n",
       "      <td>0.061525</td>\n",
       "      <td>0.145158</td>\n",
       "      <td>0.242478</td>\n",
       "      <td>0.365163</td>\n",
       "      <td>0.429993</td>\n",
       "      <td>0.470213</td>\n",
       "      <td>0.493644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.438636</td>\n",
       "      <td>0.415909</td>\n",
       "      <td>0.401907</td>\n",
       "      <td>0.389192</td>\n",
       "      <td>0.367125</td>\n",
       "      <td>0.360327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496604</td>\n",
       "      <td>0.605290</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>0.054655</td>\n",
       "      <td>0.120285</td>\n",
       "      <td>0.202636</td>\n",
       "      <td>0.303349</td>\n",
       "      <td>0.370131</td>\n",
       "      <td>0.412466</td>\n",
       "      <td>0.438627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.421591</td>\n",
       "      <td>0.406449</td>\n",
       "      <td>0.382153</td>\n",
       "      <td>0.374390</td>\n",
       "      <td>0.361689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497722</td>\n",
       "      <td>0.610006</td>\n",
       "      <td>0.028874</td>\n",
       "      <td>0.055402</td>\n",
       "      <td>0.121645</td>\n",
       "      <td>0.198971</td>\n",
       "      <td>0.309352</td>\n",
       "      <td>0.371531</td>\n",
       "      <td>0.413395</td>\n",
       "      <td>0.442044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.343182</td>\n",
       "      <td>0.357955</td>\n",
       "      <td>0.461399</td>\n",
       "      <td>0.448910</td>\n",
       "      <td>0.430015</td>\n",
       "      <td>0.414592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548550</td>\n",
       "      <td>0.674179</td>\n",
       "      <td>0.023315</td>\n",
       "      <td>0.047039</td>\n",
       "      <td>0.138090</td>\n",
       "      <td>0.233729</td>\n",
       "      <td>0.355314</td>\n",
       "      <td>0.425873</td>\n",
       "      <td>0.455611</td>\n",
       "      <td>0.488548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'log2', 'min...</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.351136</td>\n",
       "      <td>0.345595</td>\n",
       "      <td>0.327430</td>\n",
       "      <td>0.371325</td>\n",
       "      <td>0.337546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.458084</td>\n",
       "      <td>0.645169</td>\n",
       "      <td>0.023161</td>\n",
       "      <td>0.046144</td>\n",
       "      <td>0.103432</td>\n",
       "      <td>0.170479</td>\n",
       "      <td>0.306819</td>\n",
       "      <td>0.346731</td>\n",
       "      <td>0.380472</td>\n",
       "      <td>0.467526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.356818</td>\n",
       "      <td>0.461853</td>\n",
       "      <td>0.448910</td>\n",
       "      <td>0.430015</td>\n",
       "      <td>0.413986</td>\n",
       "      <td>...</td>\n",
       "      <td>0.548550</td>\n",
       "      <td>0.674179</td>\n",
       "      <td>0.023161</td>\n",
       "      <td>0.046890</td>\n",
       "      <td>0.138226</td>\n",
       "      <td>0.233729</td>\n",
       "      <td>0.355314</td>\n",
       "      <td>0.425251</td>\n",
       "      <td>0.455611</td>\n",
       "      <td>0.488548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 10, 'min...</td>\n",
       "      <td>0.340909</td>\n",
       "      <td>0.355682</td>\n",
       "      <td>0.461853</td>\n",
       "      <td>0.448910</td>\n",
       "      <td>0.430582</td>\n",
       "      <td>0.413683</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549029</td>\n",
       "      <td>0.674898</td>\n",
       "      <td>0.023161</td>\n",
       "      <td>0.046741</td>\n",
       "      <td>0.138226</td>\n",
       "      <td>0.233729</td>\n",
       "      <td>0.355783</td>\n",
       "      <td>0.424940</td>\n",
       "      <td>0.456009</td>\n",
       "      <td>0.489069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 0.001, 'penalty': 'l1'}</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.357955</td>\n",
       "      <td>0.396458</td>\n",
       "      <td>0.414623</td>\n",
       "      <td>0.428539</td>\n",
       "      <td>0.417619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562535</td>\n",
       "      <td>0.676337</td>\n",
       "      <td>0.020999</td>\n",
       "      <td>0.047039</td>\n",
       "      <td>0.118654</td>\n",
       "      <td>0.215878</td>\n",
       "      <td>0.354094</td>\n",
       "      <td>0.428982</td>\n",
       "      <td>0.467226</td>\n",
       "      <td>0.490111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>{'max_depth': 50, 'max_features': 'sqrt', 'min...</td>\n",
       "      <td>0.309091</td>\n",
       "      <td>0.357955</td>\n",
       "      <td>0.351045</td>\n",
       "      <td>0.334015</td>\n",
       "      <td>0.372233</td>\n",
       "      <td>0.341331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.464637</td>\n",
       "      <td>0.647327</td>\n",
       "      <td>0.020999</td>\n",
       "      <td>0.047039</td>\n",
       "      <td>0.105063</td>\n",
       "      <td>0.173908</td>\n",
       "      <td>0.307570</td>\n",
       "      <td>0.350618</td>\n",
       "      <td>0.385915</td>\n",
       "      <td>0.469089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.302273</td>\n",
       "      <td>0.365909</td>\n",
       "      <td>0.436876</td>\n",
       "      <td>0.423933</td>\n",
       "      <td>0.410603</td>\n",
       "      <td>0.412775</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555662</td>\n",
       "      <td>0.672820</td>\n",
       "      <td>0.020536</td>\n",
       "      <td>0.048085</td>\n",
       "      <td>0.130751</td>\n",
       "      <td>0.220725</td>\n",
       "      <td>0.339274</td>\n",
       "      <td>0.424007</td>\n",
       "      <td>0.461518</td>\n",
       "      <td>0.487563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.361364</td>\n",
       "      <td>0.435059</td>\n",
       "      <td>0.428474</td>\n",
       "      <td>0.411057</td>\n",
       "      <td>0.413381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.554304</td>\n",
       "      <td>0.673699</td>\n",
       "      <td>0.020381</td>\n",
       "      <td>0.047487</td>\n",
       "      <td>0.130207</td>\n",
       "      <td>0.223089</td>\n",
       "      <td>0.339649</td>\n",
       "      <td>0.424629</td>\n",
       "      <td>0.460390</td>\n",
       "      <td>0.488200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>{'C': 1e-05, 'penalty': 'l1'}</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.276136</td>\n",
       "      <td>0.268392</td>\n",
       "      <td>0.250681</td>\n",
       "      <td>0.293790</td>\n",
       "      <td>0.288277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.403261</td>\n",
       "      <td>0.498601</td>\n",
       "      <td>0.020381</td>\n",
       "      <td>0.036288</td>\n",
       "      <td>0.080326</td>\n",
       "      <td>0.130520</td>\n",
       "      <td>0.242754</td>\n",
       "      <td>0.296121</td>\n",
       "      <td>0.334937</td>\n",
       "      <td>0.361315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.108311</td>\n",
       "      <td>0.348734</td>\n",
       "      <td>0.329902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.450332</td>\n",
       "      <td>0.730520</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.056393</td>\n",
       "      <td>0.288153</td>\n",
       "      <td>0.338879</td>\n",
       "      <td>0.374033</td>\n",
       "      <td>0.529376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.310932</td>\n",
       "      <td>0.338833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563494</td>\n",
       "      <td>0.915448</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.256918</td>\n",
       "      <td>0.348053</td>\n",
       "      <td>0.468023</td>\n",
       "      <td>0.663385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 100, 'mi...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.059037</td>\n",
       "      <td>0.357402</td>\n",
       "      <td>0.356340</td>\n",
       "      <td>0.335276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475186</td>\n",
       "      <td>0.590106</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.017669</td>\n",
       "      <td>0.186085</td>\n",
       "      <td>0.294438</td>\n",
       "      <td>0.344399</td>\n",
       "      <td>0.394677</td>\n",
       "      <td>0.427624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.055404</td>\n",
       "      <td>0.358765</td>\n",
       "      <td>0.357362</td>\n",
       "      <td>0.336184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.479901</td>\n",
       "      <td>0.590666</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.016582</td>\n",
       "      <td>0.186794</td>\n",
       "      <td>0.295282</td>\n",
       "      <td>0.345332</td>\n",
       "      <td>0.398593</td>\n",
       "      <td>0.428030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.109446</td>\n",
       "      <td>0.347599</td>\n",
       "      <td>0.327935</td>\n",
       "      <td>...</td>\n",
       "      <td>0.447774</td>\n",
       "      <td>0.729242</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.056984</td>\n",
       "      <td>0.287215</td>\n",
       "      <td>0.336858</td>\n",
       "      <td>0.371909</td>\n",
       "      <td>0.528449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 50, 'min...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.311046</td>\n",
       "      <td>0.338757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563894</td>\n",
       "      <td>0.915848</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.257012</td>\n",
       "      <td>0.347975</td>\n",
       "      <td>0.468355</td>\n",
       "      <td>0.663675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'min...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.310627</td>\n",
       "      <td>0.348547</td>\n",
       "      <td>0.365762</td>\n",
       "      <td>0.359873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.494286</td>\n",
       "      <td>0.606729</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.092966</td>\n",
       "      <td>0.181474</td>\n",
       "      <td>0.302223</td>\n",
       "      <td>0.369665</td>\n",
       "      <td>0.410541</td>\n",
       "      <td>0.439670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'min...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.330381</td>\n",
       "      <td>0.359973</td>\n",
       "      <td>0.358359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.496843</td>\n",
       "      <td>0.606329</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.172016</td>\n",
       "      <td>0.297439</td>\n",
       "      <td>0.368110</td>\n",
       "      <td>0.412665</td>\n",
       "      <td>0.439380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 20, 'min...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.325159</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.358208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500360</td>\n",
       "      <td>0.601614</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.169297</td>\n",
       "      <td>0.287403</td>\n",
       "      <td>0.367955</td>\n",
       "      <td>0.415585</td>\n",
       "      <td>0.435964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.310818</td>\n",
       "      <td>0.333611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.554144</td>\n",
       "      <td>0.906098</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.256824</td>\n",
       "      <td>0.342688</td>\n",
       "      <td>0.460257</td>\n",
       "      <td>0.656609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.265441</td>\n",
       "      <td>0.396753</td>\n",
       "      <td>0.394914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546552</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.138204</td>\n",
       "      <td>0.327830</td>\n",
       "      <td>0.405660</td>\n",
       "      <td>0.453951</td>\n",
       "      <td>0.505574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.313089</td>\n",
       "      <td>0.327859</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547511</td>\n",
       "      <td>0.899465</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.258700</td>\n",
       "      <td>0.336780</td>\n",
       "      <td>0.454748</td>\n",
       "      <td>0.651803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.265441</td>\n",
       "      <td>0.396753</td>\n",
       "      <td>0.394838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546711</td>\n",
       "      <td>0.684328</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.138204</td>\n",
       "      <td>0.327830</td>\n",
       "      <td>0.405582</td>\n",
       "      <td>0.454084</td>\n",
       "      <td>0.495903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.265441</td>\n",
       "      <td>0.396753</td>\n",
       "      <td>0.394838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546711</td>\n",
       "      <td>0.684328</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.138204</td>\n",
       "      <td>0.327830</td>\n",
       "      <td>0.405582</td>\n",
       "      <td>0.454084</td>\n",
       "      <td>0.495903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 5, 'min_sam...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.265441</td>\n",
       "      <td>0.396753</td>\n",
       "      <td>0.394838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546711</td>\n",
       "      <td>0.684328</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.138204</td>\n",
       "      <td>0.327830</td>\n",
       "      <td>0.405582</td>\n",
       "      <td>0.454084</td>\n",
       "      <td>0.495903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.240690</td>\n",
       "      <td>0.337836</td>\n",
       "      <td>0.352532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.491649</td>\n",
       "      <td>0.591145</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.125318</td>\n",
       "      <td>0.279148</td>\n",
       "      <td>0.362124</td>\n",
       "      <td>0.408350</td>\n",
       "      <td>0.428377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.314260</td>\n",
       "      <td>0.350664</td>\n",
       "      <td>0.350488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489411</td>\n",
       "      <td>0.595301</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.163622</td>\n",
       "      <td>0.289748</td>\n",
       "      <td>0.360025</td>\n",
       "      <td>0.406492</td>\n",
       "      <td>0.431388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.265441</td>\n",
       "      <td>0.396753</td>\n",
       "      <td>0.394914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546552</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.138204</td>\n",
       "      <td>0.327830</td>\n",
       "      <td>0.405660</td>\n",
       "      <td>0.453951</td>\n",
       "      <td>0.505574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 20, 'min_sa...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.298819</td>\n",
       "      <td>0.347866</td>\n",
       "      <td>0.357475</td>\n",
       "      <td>0.355559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.495884</td>\n",
       "      <td>0.598258</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.089433</td>\n",
       "      <td>0.181120</td>\n",
       "      <td>0.295376</td>\n",
       "      <td>0.365234</td>\n",
       "      <td>0.411868</td>\n",
       "      <td>0.433531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.155767</td>\n",
       "      <td>0.346464</td>\n",
       "      <td>0.331946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454807</td>\n",
       "      <td>0.695437</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.081102</td>\n",
       "      <td>0.286277</td>\n",
       "      <td>0.340978</td>\n",
       "      <td>0.377750</td>\n",
       "      <td>0.503953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 50, 'min_sa...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.185740</td>\n",
       "      <td>0.360127</td>\n",
       "      <td>0.345102</td>\n",
       "      <td>0.338076</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475585</td>\n",
       "      <td>0.583154</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.055590</td>\n",
       "      <td>0.187504</td>\n",
       "      <td>0.285151</td>\n",
       "      <td>0.347275</td>\n",
       "      <td>0.395008</td>\n",
       "      <td>0.422586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.160536</td>\n",
       "      <td>0.345896</td>\n",
       "      <td>0.331492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454647</td>\n",
       "      <td>0.693199</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.083585</td>\n",
       "      <td>0.285808</td>\n",
       "      <td>0.340512</td>\n",
       "      <td>0.377618</td>\n",
       "      <td>0.502331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 100, 'min_s...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.173933</td>\n",
       "      <td>0.350363</td>\n",
       "      <td>0.345896</td>\n",
       "      <td>0.338303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.475346</td>\n",
       "      <td>0.584113</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.052056</td>\n",
       "      <td>0.182420</td>\n",
       "      <td>0.285808</td>\n",
       "      <td>0.347508</td>\n",
       "      <td>0.394809</td>\n",
       "      <td>0.423281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 5, 'min_...</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.265441</td>\n",
       "      <td>0.396753</td>\n",
       "      <td>0.394914</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546552</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.138204</td>\n",
       "      <td>0.327830</td>\n",
       "      <td>0.405660</td>\n",
       "      <td>0.453951</td>\n",
       "      <td>0.505574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527771</td>\n",
       "      <td>0.856709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.171033</td>\n",
       "      <td>0.438353</td>\n",
       "      <td>0.620819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527771</td>\n",
       "      <td>0.856709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.171033</td>\n",
       "      <td>0.438353</td>\n",
       "      <td>0.620819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527771</td>\n",
       "      <td>0.856709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.171033</td>\n",
       "      <td>0.438353</td>\n",
       "      <td>0.620819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527771</td>\n",
       "      <td>0.856709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.171033</td>\n",
       "      <td>0.438353</td>\n",
       "      <td>0.620819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'gini', 'max_depth': 1, 'min_sam...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527771</td>\n",
       "      <td>0.856709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.171033</td>\n",
       "      <td>0.438353</td>\n",
       "      <td>0.620819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>{'criterion': 'entropy', 'max_depth': 1, 'min_...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166503</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527771</td>\n",
       "      <td>0.856709</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.171033</td>\n",
       "      <td>0.438353</td>\n",
       "      <td>0.620819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_end_date model_type  \\\n",
       "125     2013-05-02         RF   \n",
       "129     2013-05-02         RF   \n",
       "127     2013-05-02         RF   \n",
       "131     2013-05-02         RF   \n",
       "124     2013-05-02         RF   \n",
       "182     2013-05-02         LR   \n",
       "185     2013-05-02         LR   \n",
       "184     2013-05-02         LR   \n",
       "183     2013-05-02         LR   \n",
       "181     2013-05-02         LR   \n",
       "180     2013-05-02         LR   \n",
       "135     2013-05-02         RF   \n",
       "138     2013-05-02         RF   \n",
       "139     2013-05-02         RF   \n",
       "134     2013-05-02         RF   \n",
       "128     2013-05-02         RF   \n",
       "130     2013-05-02         RF   \n",
       "179     2013-05-02         LR   \n",
       "126     2013-05-02         RF   \n",
       "133     2013-05-02         RF   \n",
       "137     2013-05-02         RF   \n",
       "164     2013-05-02         DT   \n",
       "136     2013-05-02         RF   \n",
       "165     2013-05-02         DT   \n",
       "166     2013-05-02         DT   \n",
       "178     2013-05-02         LR   \n",
       "132     2013-05-02         RF   \n",
       "147     2013-05-02         DT   \n",
       "148     2013-05-02         DT   \n",
       "176     2013-05-02         LR   \n",
       "..             ...        ...   \n",
       "174     2013-05-02         DT   \n",
       "173     2013-05-02         DT   \n",
       "175     2013-05-02         DT   \n",
       "172     2013-05-02         DT   \n",
       "171     2013-05-02         DT   \n",
       "170     2013-05-02         DT   \n",
       "169     2013-05-02         DT   \n",
       "168     2013-05-02         DT   \n",
       "167     2013-05-02         DT   \n",
       "155     2013-05-02         DT   \n",
       "163     2013-05-02         DT   \n",
       "152     2013-05-02         DT   \n",
       "143     2013-05-02         DT   \n",
       "144     2013-05-02         DT   \n",
       "145     2013-05-02         DT   \n",
       "149     2013-05-02         DT   \n",
       "150     2013-05-02         DT   \n",
       "162     2013-05-02         DT   \n",
       "151     2013-05-02         DT   \n",
       "153     2013-05-02         DT   \n",
       "154     2013-05-02         DT   \n",
       "156     2013-05-02         DT   \n",
       "157     2013-05-02         DT   \n",
       "161     2013-05-02         DT   \n",
       "159     2013-05-02         DT   \n",
       "160     2013-05-02         DT   \n",
       "142     2013-05-02         DT   \n",
       "141     2013-05-02         DT   \n",
       "140     2013-05-02         DT   \n",
       "158     2013-05-02         DT   \n",
       "\n",
       "                                                   clf  \\\n",
       "125  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "129  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "127  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "131  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "124  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "182  LogisticRegression(C=10, class_weight=None, du...   \n",
       "185  LogisticRegression(C=10, class_weight=None, du...   \n",
       "184  LogisticRegression(C=10, class_weight=None, du...   \n",
       "183  LogisticRegression(C=10, class_weight=None, du...   \n",
       "181  LogisticRegression(C=10, class_weight=None, du...   \n",
       "180  LogisticRegression(C=10, class_weight=None, du...   \n",
       "135  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "138  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "139  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "134  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "128  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "130  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "179  LogisticRegression(C=10, class_weight=None, du...   \n",
       "126  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "133  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "137  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "164  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "136  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "165  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "166  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "178  LogisticRegression(C=10, class_weight=None, du...   \n",
       "132  (DecisionTreeClassifier(class_weight=None, cri...   \n",
       "147  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "148  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "176  LogisticRegression(C=10, class_weight=None, du...   \n",
       "..                                                 ...   \n",
       "174  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "173  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "175  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "172  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "171  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "170  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "169  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "168  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "167  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "155  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "163  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "152  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "143  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "144  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "145  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "149  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "150  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "162  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "151  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "153  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "154  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "156  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "157  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "161  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "159  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "160  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "142  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "141  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "140  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "158  DecisionTreeClassifier(class_weight=None, crit...   \n",
       "\n",
       "                                            parameters  p_at_1.0  p_at_2.0  \\\n",
       "125  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.554545  0.532955   \n",
       "129  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.550000  0.501136   \n",
       "127  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.534091  0.512500   \n",
       "131  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.515909  0.497727   \n",
       "124  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.502273  0.496591   \n",
       "182                          {'C': 1, 'penalty': 'l1'}  0.500000  0.517045   \n",
       "185                         {'C': 10, 'penalty': 'l2'}  0.497727  0.517045   \n",
       "184                         {'C': 10, 'penalty': 'l1'}  0.495455  0.517045   \n",
       "183                          {'C': 1, 'penalty': 'l2'}  0.495455  0.515909   \n",
       "181                        {'C': 0.1, 'penalty': 'l2'}  0.495455  0.515909   \n",
       "180                        {'C': 0.1, 'penalty': 'l1'}  0.493182  0.515909   \n",
       "135  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.488636  0.464773   \n",
       "138  {'max_depth': 50, 'max_features': 'log2', 'min...  0.488636  0.478409   \n",
       "139  {'max_depth': 50, 'max_features': 'log2', 'min...  0.481818  0.462500   \n",
       "134  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.461364  0.461364   \n",
       "128  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.456818  0.461364   \n",
       "130  {'max_depth': 5, 'max_features': 'log2', 'min_...  0.452273  0.473864   \n",
       "179                      {'C': 0.001, 'penalty': 'l2'}  0.450000  0.460227   \n",
       "126  {'max_depth': 5, 'max_features': 'sqrt', 'min_...  0.447727  0.468182   \n",
       "133  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.438636  0.415909   \n",
       "137  {'max_depth': 50, 'max_features': 'log2', 'min...  0.425000  0.421591   \n",
       "164  {'criterion': 'entropy', 'max_depth': 10, 'min...  0.343182  0.357955   \n",
       "136  {'max_depth': 50, 'max_features': 'log2', 'min...  0.340909  0.351136   \n",
       "165  {'criterion': 'entropy', 'max_depth': 10, 'min...  0.340909  0.356818   \n",
       "166  {'criterion': 'entropy', 'max_depth': 10, 'min...  0.340909  0.355682   \n",
       "178                      {'C': 0.001, 'penalty': 'l1'}  0.309091  0.357955   \n",
       "132  {'max_depth': 50, 'max_features': 'sqrt', 'min...  0.309091  0.357955   \n",
       "147  {'criterion': 'gini', 'max_depth': 10, 'min_sa...  0.302273  0.365909   \n",
       "148  {'criterion': 'gini', 'max_depth': 10, 'min_sa...  0.300000  0.361364   \n",
       "176                      {'C': 1e-05, 'penalty': 'l1'}  0.300000  0.276136   \n",
       "..                                                 ...       ...       ...   \n",
       "174  {'criterion': 'entropy', 'max_depth': 100, 'mi...  0.002273  0.001136   \n",
       "173  {'criterion': 'entropy', 'max_depth': 100, 'mi...  0.002273  0.001136   \n",
       "175  {'criterion': 'entropy', 'max_depth': 100, 'mi...  0.002273  0.001136   \n",
       "172  {'criterion': 'entropy', 'max_depth': 50, 'min...  0.002273  0.001136   \n",
       "171  {'criterion': 'entropy', 'max_depth': 50, 'min...  0.002273  0.001136   \n",
       "170  {'criterion': 'entropy', 'max_depth': 50, 'min...  0.002273  0.001136   \n",
       "169  {'criterion': 'entropy', 'max_depth': 20, 'min...  0.002273  0.001136   \n",
       "168  {'criterion': 'entropy', 'max_depth': 20, 'min...  0.002273  0.001136   \n",
       "167  {'criterion': 'entropy', 'max_depth': 20, 'min...  0.002273  0.001136   \n",
       "155  {'criterion': 'gini', 'max_depth': 100, 'min_s...  0.002273  0.001136   \n",
       "163  {'criterion': 'entropy', 'max_depth': 5, 'min_...  0.002273  0.001136   \n",
       "152  {'criterion': 'gini', 'max_depth': 50, 'min_sa...  0.002273  0.001136   \n",
       "143  {'criterion': 'gini', 'max_depth': 5, 'min_sam...  0.002273  0.001136   \n",
       "144  {'criterion': 'gini', 'max_depth': 5, 'min_sam...  0.002273  0.001136   \n",
       "145  {'criterion': 'gini', 'max_depth': 5, 'min_sam...  0.002273  0.001136   \n",
       "149  {'criterion': 'gini', 'max_depth': 20, 'min_sa...  0.002273  0.001136   \n",
       "150  {'criterion': 'gini', 'max_depth': 20, 'min_sa...  0.002273  0.001136   \n",
       "162  {'criterion': 'entropy', 'max_depth': 5, 'min_...  0.002273  0.001136   \n",
       "151  {'criterion': 'gini', 'max_depth': 20, 'min_sa...  0.002273  0.001136   \n",
       "153  {'criterion': 'gini', 'max_depth': 50, 'min_sa...  0.002273  0.001136   \n",
       "154  {'criterion': 'gini', 'max_depth': 50, 'min_sa...  0.002273  0.001136   \n",
       "156  {'criterion': 'gini', 'max_depth': 100, 'min_s...  0.002273  0.001136   \n",
       "157  {'criterion': 'gini', 'max_depth': 100, 'min_s...  0.002273  0.001136   \n",
       "161  {'criterion': 'entropy', 'max_depth': 5, 'min_...  0.002273  0.001136   \n",
       "159  {'criterion': 'entropy', 'max_depth': 1, 'min_...  0.000000  0.000000   \n",
       "160  {'criterion': 'entropy', 'max_depth': 1, 'min_...  0.000000  0.000000   \n",
       "142  {'criterion': 'gini', 'max_depth': 1, 'min_sam...  0.000000  0.000000   \n",
       "141  {'criterion': 'gini', 'max_depth': 1, 'min_sam...  0.000000  0.000000   \n",
       "140  {'criterion': 'gini', 'max_depth': 1, 'min_sam...  0.000000  0.000000   \n",
       "158  {'criterion': 'entropy', 'max_depth': 1, 'min_...  0.000000  0.000000   \n",
       "\n",
       "     p_at_5.0  p_at_10.0  p_at_20.0  p_at_30.0     ...      r_at_40.0  \\\n",
       "125  0.497729   0.483651   0.444205   0.420798     ...       0.571965   \n",
       "129  0.493188   0.474796   0.442161   0.420192     ...       0.570686   \n",
       "127  0.497729   0.483197   0.445113   0.420873     ...       0.571086   \n",
       "131  0.487738   0.478429   0.444659   0.417543     ...       0.568129   \n",
       "124  0.496821   0.482516   0.444886   0.416484     ...       0.562135   \n",
       "182  0.495913   0.482970   0.449994   0.428593     ...       0.578279   \n",
       "185  0.496821   0.483424   0.449881   0.428896     ...       0.577799   \n",
       "184  0.495913   0.483651   0.449881   0.428669     ...       0.577959   \n",
       "183  0.495005   0.482743   0.449767   0.428517     ...       0.578199   \n",
       "181  0.495913   0.482970   0.449200   0.428820     ...       0.577959   \n",
       "180  0.493188   0.483878   0.449200   0.428290     ...       0.578199   \n",
       "135  0.447321   0.434832   0.416960   0.397412     ...       0.537281   \n",
       "138  0.439146   0.414623   0.401294   0.385075     ...       0.520738   \n",
       "139  0.454587   0.431653   0.415144   0.397109     ...       0.534884   \n",
       "134  0.443233   0.424614   0.407651   0.391433     ...       0.532326   \n",
       "128  0.466848   0.447548   0.438415   0.423522     ...       0.572604   \n",
       "130  0.460490   0.453224   0.435350   0.413608     ...       0.560697   \n",
       "179  0.473660   0.468211   0.442275   0.425490     ...       0.576760   \n",
       "126  0.485014   0.465713   0.441934   0.418603     ...       0.566131   \n",
       "133  0.401907   0.389192   0.367125   0.360327     ...       0.496604   \n",
       "137  0.406449   0.382153   0.374390   0.361689     ...       0.497722   \n",
       "164  0.461399   0.448910   0.430015   0.414592     ...       0.548550   \n",
       "136  0.345595   0.327430   0.371325   0.337546     ...       0.458084   \n",
       "165  0.461853   0.448910   0.430015   0.413986     ...       0.548550   \n",
       "166  0.461853   0.448910   0.430582   0.413683     ...       0.549029   \n",
       "178  0.396458   0.414623   0.428539   0.417619     ...       0.562535   \n",
       "132  0.351045   0.334015   0.372233   0.341331     ...       0.464637   \n",
       "147  0.436876   0.423933   0.410603   0.412775     ...       0.555662   \n",
       "148  0.435059   0.428474   0.411057   0.413381     ...       0.554304   \n",
       "176  0.268392   0.250681   0.293790   0.288277     ...       0.403261   \n",
       "..        ...        ...        ...        ...     ...            ...   \n",
       "174  0.000454   0.108311   0.348734   0.329902     ...       0.450332   \n",
       "173  0.000454   0.000227   0.310932   0.338833     ...       0.563494   \n",
       "175  0.059037   0.357402   0.356340   0.335276     ...       0.475186   \n",
       "172  0.055404   0.358765   0.357362   0.336184     ...       0.479901   \n",
       "171  0.000454   0.109446   0.347599   0.327935     ...       0.447774   \n",
       "170  0.000454   0.000227   0.311046   0.338757     ...       0.563894   \n",
       "169  0.310627   0.348547   0.365762   0.359873     ...       0.494286   \n",
       "168  0.000454   0.330381   0.359973   0.358359     ...       0.496843   \n",
       "167  0.000454   0.325159   0.347826   0.358208     ...       0.500360   \n",
       "155  0.000454   0.000227   0.310818   0.333611     ...       0.554144   \n",
       "163  0.000454   0.265441   0.396753   0.394914     ...       0.546552   \n",
       "152  0.000454   0.000227   0.313089   0.327859     ...       0.547511   \n",
       "143  0.000454   0.265441   0.396753   0.394838     ...       0.546711   \n",
       "144  0.000454   0.265441   0.396753   0.394838     ...       0.546711   \n",
       "145  0.000454   0.265441   0.396753   0.394838     ...       0.546711   \n",
       "149  0.000454   0.240690   0.337836   0.352532     ...       0.491649   \n",
       "150  0.000454   0.314260   0.350664   0.350488     ...       0.489411   \n",
       "162  0.000454   0.265441   0.396753   0.394914     ...       0.546552   \n",
       "151  0.298819   0.347866   0.357475   0.355559     ...       0.495884   \n",
       "153  0.000454   0.155767   0.346464   0.331946     ...       0.454807   \n",
       "154  0.185740   0.360127   0.345102   0.338076     ...       0.475585   \n",
       "156  0.000454   0.160536   0.345896   0.331492     ...       0.454647   \n",
       "157  0.173933   0.350363   0.345896   0.338303     ...       0.475346   \n",
       "161  0.000454   0.265441   0.396753   0.394914     ...       0.546552   \n",
       "159  0.000000   0.000000   0.000000   0.166503     ...       0.527771   \n",
       "160  0.000000   0.000000   0.000000   0.166503     ...       0.527771   \n",
       "142  0.000000   0.000000   0.000000   0.166503     ...       0.527771   \n",
       "141  0.000000   0.000000   0.000000   0.166503     ...       0.527771   \n",
       "140  0.000000   0.000000   0.000000   0.166503     ...       0.527771   \n",
       "158  0.000000   0.000000   0.000000   0.166503     ...       0.527771   \n",
       "\n",
       "     r_at_50.0  f1_at_1.0  f1_at_2.0  f1_at_5.0  f1_at_10.0  f1_at_20.0  \\\n",
       "125   0.687445   0.037675   0.070037   0.148964    0.251818    0.367039   \n",
       "129   0.687685   0.037366   0.065855   0.147604    0.247207    0.365350   \n",
       "127   0.686646   0.036285   0.067349   0.148964    0.251581    0.367789   \n",
       "131   0.686646   0.035050   0.065407   0.145973    0.249099    0.367414   \n",
       "124   0.682730   0.034123   0.065258   0.148692    0.251227    0.367602   \n",
       "182   0.689763   0.033969   0.067946   0.148420    0.251463    0.371823   \n",
       "185   0.689763   0.033815   0.067946   0.148692    0.251699    0.371729   \n",
       "184   0.689683   0.033660   0.067946   0.148420    0.251818    0.371729   \n",
       "183   0.689683   0.033660   0.067797   0.148148    0.251345    0.371635   \n",
       "181   0.689523   0.033660   0.067797   0.148420    0.251463    0.371166   \n",
       "180   0.689523   0.033506   0.067797   0.147604    0.251936    0.371166   \n",
       "135   0.646288   0.033197   0.061077   0.133877    0.226399    0.344527   \n",
       "138   0.631903   0.033197   0.062869   0.131431    0.215878    0.331582   \n",
       "139   0.642292   0.032734   0.060778   0.136052    0.224744    0.343026   \n",
       "134   0.637097   0.031344   0.060629   0.132654    0.221079    0.336835   \n",
       "128   0.683209   0.031035   0.060629   0.139721    0.233020    0.362255   \n",
       "130   0.673460   0.030726   0.062271   0.137819    0.235976    0.359722   \n",
       "179   0.688963   0.030572   0.060479   0.141760    0.243778    0.365444   \n",
       "126   0.681212   0.030418   0.061525   0.145158    0.242478    0.365163   \n",
       "133   0.605290   0.029800   0.054655   0.120285    0.202636    0.303349   \n",
       "137   0.610006   0.028874   0.055402   0.121645    0.198971    0.309352   \n",
       "164   0.674179   0.023315   0.047039   0.138090    0.233729    0.355314   \n",
       "136   0.645169   0.023161   0.046144   0.103432    0.170479    0.306819   \n",
       "165   0.674179   0.023161   0.046890   0.138226    0.233729    0.355314   \n",
       "166   0.674898   0.023161   0.046741   0.138226    0.233729    0.355783   \n",
       "178   0.676337   0.020999   0.047039   0.118654    0.215878    0.354094   \n",
       "132   0.647327   0.020999   0.047039   0.105063    0.173908    0.307570   \n",
       "147   0.672820   0.020536   0.048085   0.130751    0.220725    0.339274   \n",
       "148   0.673699   0.020381   0.047487   0.130207    0.223089    0.339649   \n",
       "176   0.498601   0.020381   0.036288   0.080326    0.130520    0.242754   \n",
       "..         ...        ...        ...        ...         ...         ...   \n",
       "174   0.730520   0.000154   0.000149   0.000136    0.056393    0.288153   \n",
       "173   0.915448   0.000154   0.000149   0.000136    0.000118    0.256918   \n",
       "175   0.590106   0.000154   0.000149   0.017669    0.186085    0.294438   \n",
       "172   0.590666   0.000154   0.000149   0.016582    0.186794    0.295282   \n",
       "171   0.729242   0.000154   0.000149   0.000136    0.056984    0.287215   \n",
       "170   0.915848   0.000154   0.000149   0.000136    0.000118    0.257012   \n",
       "169   0.606729   0.000154   0.000149   0.092966    0.181474    0.302223   \n",
       "168   0.606329   0.000154   0.000149   0.000136    0.172016    0.297439   \n",
       "167   0.601614   0.000154   0.000149   0.000136    0.169297    0.287403   \n",
       "155   0.906098   0.000154   0.000149   0.000136    0.000118    0.256824   \n",
       "163   0.697674   0.000154   0.000149   0.000136    0.138204    0.327830   \n",
       "152   0.899465   0.000154   0.000149   0.000136    0.000118    0.258700   \n",
       "143   0.684328   0.000154   0.000149   0.000136    0.138204    0.327830   \n",
       "144   0.684328   0.000154   0.000149   0.000136    0.138204    0.327830   \n",
       "145   0.684328   0.000154   0.000149   0.000136    0.138204    0.327830   \n",
       "149   0.591145   0.000154   0.000149   0.000136    0.125318    0.279148   \n",
       "150   0.595301   0.000154   0.000149   0.000136    0.163622    0.289748   \n",
       "162   0.697674   0.000154   0.000149   0.000136    0.138204    0.327830   \n",
       "151   0.598258   0.000154   0.000149   0.089433    0.181120    0.295376   \n",
       "153   0.695437   0.000154   0.000149   0.000136    0.081102    0.286277   \n",
       "154   0.583154   0.000154   0.000149   0.055590    0.187504    0.285151   \n",
       "156   0.693199   0.000154   0.000149   0.000136    0.083585    0.285808   \n",
       "157   0.584113   0.000154   0.000149   0.052056    0.182420    0.285808   \n",
       "161   0.697674   0.000154   0.000149   0.000136    0.138204    0.327830   \n",
       "159   0.856709        NaN        NaN        NaN         NaN         NaN   \n",
       "160   0.856709        NaN        NaN        NaN         NaN         NaN   \n",
       "142   0.856709        NaN        NaN        NaN         NaN         NaN   \n",
       "141   0.856709        NaN        NaN        NaN         NaN         NaN   \n",
       "140   0.856709        NaN        NaN        NaN         NaN         NaN   \n",
       "158   0.856709        NaN        NaN        NaN         NaN         NaN   \n",
       "\n",
       "     f1_at_30.0  f1_at_40.0  f1_at_50.0  \n",
       "125    0.432248    0.475059    0.498161  \n",
       "129    0.431626    0.473997    0.498335  \n",
       "127    0.432325    0.474329    0.497582  \n",
       "131    0.428905    0.471873    0.497582  \n",
       "124    0.427816    0.466895    0.494744  \n",
       "182    0.440255    0.480303    0.499841  \n",
       "185    0.440566    0.479904    0.499841  \n",
       "184    0.440333    0.480037    0.499783  \n",
       "183    0.440177    0.480236    0.499783  \n",
       "181    0.440488    0.480037    0.499667  \n",
       "180    0.439944    0.480236    0.499667  \n",
       "135    0.408225    0.446251    0.468336  \n",
       "138    0.395553    0.432511    0.457912  \n",
       "139    0.407914    0.444260    0.465441  \n",
       "134    0.402083    0.442136    0.461677  \n",
       "128    0.435046    0.475590    0.495092  \n",
       "130    0.424862    0.465700    0.488027  \n",
       "179    0.437068    0.479042    0.499262  \n",
       "126    0.429993    0.470213    0.493644  \n",
       "133    0.370131    0.412466    0.438627  \n",
       "137    0.371531    0.413395    0.442044  \n",
       "164    0.425873    0.455611    0.488548  \n",
       "136    0.346731    0.380472    0.467526  \n",
       "165    0.425251    0.455611    0.488548  \n",
       "166    0.424940    0.456009    0.489069  \n",
       "178    0.428982    0.467226    0.490111  \n",
       "132    0.350618    0.385915    0.469089  \n",
       "147    0.424007    0.461518    0.487563  \n",
       "148    0.424629    0.460390    0.488200  \n",
       "176    0.296121    0.334937    0.361315  \n",
       "..          ...         ...         ...  \n",
       "174    0.338879    0.374033    0.529376  \n",
       "173    0.348053    0.468023    0.663385  \n",
       "175    0.344399    0.394677    0.427624  \n",
       "172    0.345332    0.398593    0.428030  \n",
       "171    0.336858    0.371909    0.528449  \n",
       "170    0.347975    0.468355    0.663675  \n",
       "169    0.369665    0.410541    0.439670  \n",
       "168    0.368110    0.412665    0.439380  \n",
       "167    0.367955    0.415585    0.435964  \n",
       "155    0.342688    0.460257    0.656609  \n",
       "163    0.405660    0.453951    0.505574  \n",
       "152    0.336780    0.454748    0.651803  \n",
       "143    0.405582    0.454084    0.495903  \n",
       "144    0.405582    0.454084    0.495903  \n",
       "145    0.405582    0.454084    0.495903  \n",
       "149    0.362124    0.408350    0.428377  \n",
       "150    0.360025    0.406492    0.431388  \n",
       "162    0.405660    0.453951    0.505574  \n",
       "151    0.365234    0.411868    0.433531  \n",
       "153    0.340978    0.377750    0.503953  \n",
       "154    0.347275    0.395008    0.422586  \n",
       "156    0.340512    0.377618    0.502331  \n",
       "157    0.347508    0.394809    0.423281  \n",
       "161    0.405660    0.453951    0.505574  \n",
       "159    0.171033    0.438353    0.620819  \n",
       "160    0.171033    0.438353    0.620819  \n",
       "142    0.171033    0.438353    0.620819  \n",
       "141    0.171033    0.438353    0.620819  \n",
       "140    0.171033    0.438353    0.620819  \n",
       "158    0.171033    0.438353    0.620819  \n",
       "\n",
       "[62 rows x 28 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-9a8104a4c39a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_col'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfrozenset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "df['new_col'] = df[frozenset(df['parameters'].items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': -1}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['parameters'][125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = {'max_depth': 5,\n",
    " 'max_features': 'sqrt',\n",
    " 'min_samples_split': 2,\n",
    " 'n_estimators': 100,\n",
    " 'n_jobs': -1}\n",
    "\n",
    "b = str(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1}\""
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "shp_file = '/Users/csolisu/Downloads/tl_2017_us_zcta510/tl_2017_us_zcta510.shp'\n",
    "geo_zcta = gpd.read_file(shp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
